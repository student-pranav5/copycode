<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Copy Text Buttons</title>
    <style>
        body {
            background-color: #f0f0f0;
            font-family: Arial, sans-serif;
            text-align: center;
        }

        button {
            margin: 10px;
            padding: 10px;
            font-size: 16px;
            background-color: #ddd;
            border: 1px solid #aaa;
            cursor: pointer;
        }

        button:hover {
            background-color: #ccc;
        }

        #copiedMsg {
            margin-top: 20px;
            font-weight: bold;
            color: green;
        }
    </style>
</head>

<body>

    <h1>Copy Text Example</h1>

    <!-- Buttons for each code block -->
   
    <button onclick="copyText(text18)">n/wRouting</button>
    <button onclick="copyText(text19)">acyclicG</button>
    <button onclick="copyText(text20)">Billboards</button>
    <button onclick="copyText(text21)">GML</button>
    <button onclick="copyText(text22)">planLocationWareh</button>
    <button onclick="copyText(text23)">clusterToNewwareh</button>
    <button onclick="copyText(text24)">shippingRouters</button>
    <button onclick="copyText(text25)">deleteBestpacking</button>
    <button onclick="copyText(text26)">deliveryRoute</button>
    <button onclick="copyText(text27)">simpleForexTrading</button>
    <button onclick="copyText(text28)">processBalanceSheet</button>
    <button onclick="copyText(text29)">generatePayroll</button>
    <button onclick="copyText(text30)">hubLS</button>
    <button onclick="copyText(text31)">transforming</button>
    <button onclick="copyText(text32)">organizing</button>
    <button onclick="copyText(text33)">generating</button>


    <p id="copiedMsg"></p>

    <script>
        // Text blocks (only a few shown here for demonstration; add all your blocks similarly)
       
        const text18 = `
        import pandas as pd; 
import networkx as nx 
import matplotlib.pyplot as plt 
pd.options.mode.chained_assignment = None sInputFileName='C:/Users/Dell/OneDrive/Desktop/DS Practical/Assess-Network-Routing-Company.csv' 
sOutputFileName1='C:/Users/Dell/OneDrive/Desktop/DS Practical/Organise-Network-Routing-Company.gml' 
sOutputFileName2='C:/Users/Dell/OneDrive/Desktop/DS Practical/Organise-Network-Routing-Company.png' 
sFileName=sInputFileName 
print('Loading :',sFileName) 
CompanyData=pd.read_csv(sFileName) 
print(CompanyData.head()) 
print(CompanyData.shape) 
G=nx.Graph() 
for i in range(CompanyData.shape[0]): 
for j in range(CompanyData.shape[0]): 
Node0=CompanyData['Company_Country_Name'][i] Node1=CompanyData['Company_Country_Name'][j] 
if Node0 != Node1: 
G.add_edge(Node0,Node1) 
for i in range(CompanyData.shape[0]): 
Node0=CompanyData['Company_Country_Name'][i] Node1=CompanyData['Company_Place_Name'][i] + '('+CompanyData['Company_Country_Name'][i]+ ')' 
if Node0 != Node1: 
G.add_edge(Node0,Node1) 
print('Nodes:', G.number_of_nodes()) 
print('Edges:', G.number_of_edges()) 
sFileName='C:/Users/Dell/OneDrive/Desktop/DS Practical' + sOutputFileName1
print('Storing :',sFileName) 
nx.write_gml(G, sOutputFileName1) 
sFileName='C:/Users/Dell/OneDrive/Desktop/DS Practical' + sOutputFileName2
print('Storing Graph Image:',sFileName) 
plt.figure(figsize=(15, 15)) 
pos=nx.spectral_layout(G,dim=2) 
nx.draw_networkx_nodes(G,pos, node_color='k', node_size=10, alpha=0.8)
nx.draw_networkx_edges(G, pos,edge_color='r', arrows=False, style='dashed')
nx.draw_networkx_labels(G,pos,font_size=12,font_family='sans -serif',font_color='b') 
plt.axis('off') ;
plt.savefig(sOutputFileName2,dpi=600) 
plt.show() 
print('Done!â€™)
        `
        const text19 = `
        import networkx as nx 
import matplotlib.pyplot as plt 
import os 
import pandas as pd 
sInputFileName="C:/Users/Dell/OneDrive/Desktop/DSPractical/Retrieve_Router_Location.csv" 
sOutputFileName1="C:/Users/Dell/OneDrive/Desktop/DS Practical/Assess-DAG-Company-Country.png" 
sOutputFileName2="C:/Users/Dell/OneDrive/Desktop/DS Practical/Assess-DAG-Company-Country-Place.png" 
Company='01-Vermeulen' 
CompanyData=pd.read_csv(sInputFileName,header=0,low_me mory=False, encoding="latin-1") 
print('Loaded Company :',CompanyData.columns.values) 
print(CompanyData) 
G1=nx.DiGraph() 
G2=nx.DiGraph() 
for i in range(CompanyData.shape[0]): 
G1.add_node(CompanyData['Country'][i]) 
sPlaceName= CompanyData['Place_Name'][i] + '-' + CompanyData['Country'][i] G2.add_node(sPlaceName) 
for n1 in G1.nodes(): 
for n2 in G1.nodes(): 
if n1 != n2: 
print('Link :',n1,' to ', n2) 
G1.add_edge(n1,n2)
print("Nodes of graph: ") 
print(G1.nodes()) 
print("Edges of graph: ")
print(G1.edges()) 
sFileDir="C:/Users/Dell/OneDrive/Desktop/DS Practical" 
if not os.path.exists(sFileDir): 
os.makedirs(sFileDir) 
plt.figure(figsize=(10, 6))
nx.draw(G1,pos=nx.spectral_layout(G1), node_color='r',edge_color='g',with_labels=True,node_size=8000 , font_size=12) plt.savefig(sOutputFileName1) # save as png
plt.show() # display 
for n1 in G2.nodes(): 
for n2 in G2.nodes(): 
if n1 != n2: 
print('Link :',n1,' to ', n2) 
G2.add_edge(n1,n2)
print("Nodes of graph: ") 
print(G2.nodes()) 
print("Edges of graph: ") 
print(G2.edges()) 
sFileDir="C:/Users/Dell/OneDrive/Desktop/DS Practical" 
if not os.path.exists(sFileDir): 
os.makedirs(sFileDir) 
plt.figure(figsize=(10, 6)) 
nx.draw(G2,pos=nx.spectral_layout(G2), node_color='r',edge_color='b',with_labels=True,node_size=8000 , font_size=12) plt.savefig(sOutputFileName2) 
plt.show()

        `
        const text20 = `
        import pandas as 
df = pd.read_csv("C:/Users/Dell/OneDrive/Desktop/DS Practical/billboard_data.csv") print("Dataset Preview:") 
print(df.head()) 
N = 5 top_songs = df.nlargest(N, 'Popularity') 
print("\nTop Songs for Billboards:") 
print(top_songs[['Title', 'Artist', 'Genre', 'Popularity']])

        `
        const text21 = `
        import pandas as 
df = pd.read_csv("C:/Users/Dell/OneDrive/Desktop/DS Practical/hydry.csv") 
with open('output.gml', 'w') as 
gml_file: gml_file.write("graph [\n") 
nodes = set(df['Source']).union(set(df['Target'])) 
for node in nodes: 
gml_file.write(f" node [\n") 
gml_file.write(f" id {node}\n") 
gml_file.write(f" label \"{node}\"\n") 
gml_file.write(f" ]\n") 
for _, row in df.iterrows(): 
gml_file.write(f" edge [\n") 
gml_file.write(f" source {row['Source']}\n") 
gml_file.write(f" target {row['Target']}\n") 
gml_file.write(f" weight {row['Weight']}\n") 
gml_file.write(f" ]\n") 
gml_file.write("]\n")
print("GML file 'output.gml' created successfully.")
        `
        const text22 = `
        import pandas as pd 
import geopy.distance 
df = pd.read_csv("C:/Users/Dell/OneDrive/Desktop/DS Practical/customer.csv") total_demand = df['Demand'].sum() 
weighted_latitude = (df['Latitude'] * df['Demand']).sum() / total_demand 
weighted_longitude = (df['Longitude'] * df['Demand']).sum() / total_demand warehouse_location = {'Latitude': weighted_latitude,'Longitude': weighted_longitude} print("Suggested Warehouse Location (Weighted by Demand):") 
print(f"Latitude:{warehouse_location['Latitude']},Longitude:{warehouse_location['Longitude']}") 
for index, row in df.iterrows(): 
coords_customer = (row['Latitude'], row['Longitude']) 
coords_warehouse=(warehouse_location['Latitude'],
warehouse_location['Longitude']) 
distance = geopy.distance.distance(coords_customer, coords_warehouse).km 
print(f"Distance from {row['Location']} to Warehouse: {distance:.2f} km")
        `

        const text23 = `
        import numpy as np 
import pandas as pd 
from sklearn.cluster 
import KMeans 
import matplotlib.pyplot as plt 
from sklearn.preprocessing 
import StandardScaler ]
data = pd.read_csv("C:/Users/Dell/OneDrive/Desktop/DS Practical/locations.csv") print(data.head()) 
X = data[['Latitude', 'Longitude']].values 
scaler = StandardScaler() 
X_scaled = scaler.fit_transform(X) 
wcss = [] 
for i in range(1, 11): 
kmeans = KMeans(n_clusters=i, init='k-means++', max_iter=300, n_init=10, random_state=42) 
kmeans.fit(X_scaled) 
wcss.append(kmeans.inertia_) 
plt.plot(range(1, 11), wcss) 
plt.title('Elbow Method to Determine Optimal k') 
plt.xlabel('Number of Clusters') 
plt.ylabel('WCSS') 
plt.show() 
optimal_clusters = 3 
kmeans = KMeans(n_clusters=optimal_clusters, init='kmeans++', max_iter=300, n_init=10, random_state=42) 
kmeans.fit(X_scaled) 
centroids = kmeans.cluster_centers_ 
centroids_original_scale = scaler.inverse_transform(centroids) 
print("Suggested new warehouse locations (Latitude, Longitude):") 
for idx, centroid in enumerate(centroids_original_scale, 1): 
print(f"Location {idx}: Latitude = {centroid[0]}, Longitude = {centroid[1]}") plt.scatter(X_scaled[:, 0], X_scaled[:, 1], c=kmeans.labels_, cmap='viridis', marker='o', label='Locations') 
plt.scatter(centroids[:, 0], centroids[:, 1], c='red', marker='x', s=200, label='Centroids') plt.title('K-Means Clustering of Locations') 
plt.xlabel('Latitude (scaled)') 
plt.ylabel('Longitude (scaled)') 
plt.legend() 
plt.show()

        `
        const text24 = `
        import numpy as np 
import pandas as pd 
from itertools 
import permutations 
import math 
def haversine(lat1, lon1, lat2, lon2): 
"""Calculate the great-circle distance between two points on the Earth.""" 
R = 6371 
dlat = math.radians(lat2 - lat1) 
dlon = math.radians(lon2 - lon1) 
a = (math.sin(dlat / 2)**2+math.cos(math.radians(lat1))*math.cos(math.radians(lat2))* math.sin(dlon / 2) ** 2) 
c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a)) 
return R * c 
try: 
data=pd.read_csv("C:/Users/Dell/OneDrive/Desktop/DSPractical/locations.csv") 
except FileNotFoundError: 
print("Error: The file was not found.") 
exit() 
if not all(col in data.columns for col in ['Latitude', 'Longitude']): 
print("Error: The CSV must contain 'Latitude' and 'Longitude' columns.") exit() 
locations = data[['Latitude', 'Longitude']].values 
num_locations = len(locations) 
distance_matrix = np.zeros((num_locations, num_locations)) 
for i in range(num_locations): 
for j in range(i + 1, num_locations): 
distance_matrix[i][j] = haversine(locations[i][0], locations[i][1], locations[j][0], locations[j][1]) distance_matrix[j][i] = distance_matrix[i][j] # Symmetric
		def total_distance(route, distance_matrix): 
"""Calculate the total distance for a given route.""" 
return sum(distance_matrix[route[i], route[i + 1]] for i in range(len(route) - 1)) 
routes = permutations(range(num_locations)) 
best_route = None 
min_distance = float('inf') 
for route in routes: 
route = list(route) + [route[0]] # Return to the start 
distance = total_distance(route, distance_matrix) 
if distance < min_distance: 
min_distance = distance 
best_route = route 
print("Optimal Shipping Route (visiting each location and returning to the start):") 
for idx in best_route: 
print(f"Location {idx + 1}: Latitude = {locations[idx][0]}, Longitude = {locations[idx][1]}") 
print(f"\nTotal Distance: {min_distance:.2f} km")
        `
        const text25 = `
        def best_packing_options(container_capacity, weights, values, n): 
dp = [[0 for x in range(container_capacity + 1)]
for x in range(n + 1)] for i in range(n + 1): 
for w in range(container_capacity + 1): 
if i == 0 or w == 0: 
dp[i][w] = 0 
elif weights[i - 1] <= w: 
dp[i][w] = max(values[i - 1] + dp[i - 1][w - weights[i - 1]], dp[i - 1][w]) 
else: 
dp[i][w] = dp[i - 1][w] 
return dp[n][container_capacity] 
def find_selected_items(container_capacity, weights, values, n, dp): 
selected_items = [] 
w = container_capacity 
for i in range(n, 0, -1): 
if dp[i][w] != dp[i - 1][w]: 
selected_items.append(i) 
w -= weights[i - 1] 
return selected_items 
weights = [10, 20, 30, 40] 
values = [60, 100, 120, 240] 
container_capacity = 50 
n = len(values) 
max_value = bestt_packing_options(container_capacity, weights, values, n) 
dp = [[0 for x in range(container_capacity + 1)] 
for x in range(n + 1)] for i in range(n + 1): 
for w in range(container_capacity + 1): 
if i == 0 or w == 0: 
dp[i][w] = 0 
elif weights[i - 1] <= w: 
dp[i][w] = max(values[i - 1] + dp[i - 1][w - weights[i - 1]], dp[i - 1][w])
else: 
dp[i][w] = dp[i - 1][w] 
selected_items = find_selected_items(container_capacity, weights, values, n, dp) 
print(f"The maximum value that can be packed in the container is: {max_value}") 
print(f"The items selected to achieve this value are: {selected_items}")
        `
        const text26 = `
        import math 
def haversine(lat1, lon1, lat2, lon2): 
"""Calculate the great-circle distance between two points on the Earth.""" 
R = 6371.0 # Earth radius in kilometers 
phi1 = math.radians(lat1) 
phi2 = math.radians(lat2) delta_
phi = math.radians(lat2 - lat1) 
delta_lambda = math.radians(lon2 - lon1) 
a = math.sin(delta_phi / 2) ** 2 + math.cos(phi1) * math.cos(phi2) * math.sin(delta_lambda / 2) ** 2 
c = 2 * math.asin(math.sqrt(a)) 
return R * c 
def create_delivery_route(locations): 
"""Create a delivery route based on given locations.""" 
route = [] total_distance = 0.0 
for i in range(len(locations) - 1): 
lat1, lon1 = locations[i] 
lat2, lon2 = locations[i + 1] 
distance = haversine(lat1, lon1, lat2, lon2) 
total_distance += distance route.append((locations[i], locations[i + 1], distance)) 
return route, total_distance 
def print_route(route, total_distance): 
"""Print the delivery route and total distance.""" 
print("Delivery Route:") 
for start, end, distance in route:
	print(f"From {start} to {end}: {distance:.2f} km") 
print(f"\nTotal Distance: {total_distance:.2f} km") 
def main(): 
delivery_locations = [
 (37.7749, -122.4194),
 (37.7849, -122.4294),
 (37.7949, -122.4394),
 (37.8049, -122.4494) 
] 
route, total_distance = create_delivery_route(delivery_locations) 
print_route(route, total_distance) 
if __name__ == "__main__": 
main()

        `
        const text27 = `
        import requests 
class ForexTradingPlanner: 
def _init_(self): 
pass 
def get_current_rate(self, base_currency, target_currency): 
url = f"https://api.exchangerateapi.com/v4/latest/{base_currency}" 
try: 
response = requests.get(url) 
response.raise_for_status() # Raise an error for bad responses 
data = response.json() 
if target_currency in data['rates']: 
return data['rates'][target_currency] 
else: print(f"Currency {target_currency} not found.") 
return None 
except Exception as e: 
print(f"Error fetching rate: {e}") 
return None 
def plan_trade(self, base_currency, target_currency, amount, desired_rate):    current_rate = self.get_current_rate(base_currency, target_currency) 
if current_rate is not None: 
print(f"Current rate for {base_currency} to {target_currency}: {current_rate}") 
if current_rate <= desired_rate: 
print(f"Consider buying {amount} {target_currency} at the current rate.") 
else: 
print(f"The current rate is higher than your desired rate. Hold off on the trade.")
			else: 
print("Could not retrieve current exchange rate.") 
def main(): 
planner = ForexTradingPlanner() 
print("Forex Trading Planner") 
print("=====================") 
base_currency = input("Enter base currency (e.g., 'USD'): ").upper() 
target_currency = input("Enter target currency (e.g., 'EUR'): ").upper() 
amount = float(input("Enter the amount in base currency you want to trade: ")) desired_rate = float(input("Enter your desired exchange rate: ")) 
print(f"\nPlanning trade for {amount} {base_currency} to {target_currency}...") planner.plan_trade(base_currency, target_currency, amount, desired_rate) 
if __name__ == "__main__": 
main()

        `
        const text28 = `
        import pandas as pd 
class BalanceSheetProcessor: 
def __init__(self, file_path): 
self.file_path = file_path 
self.data = pd.read_csv(file_path) 
def validate_data(self): 
if self.data.isnull().values.any(): 
print("Data contains missing values. Please check the file.") 
return False 
negative_accounts = ['Inventory', 'Accounts Receivable'] 
negative_entries = self.data[self.data['Account'].isin(negative_accounts) & (self.data['Amount'] < 0)] 
if not negative_entries.empty: 
print("Data contains negative amounts for the following accounts:") print(negative_entries) 
return False 
return True 
def process_data(self): 
if not self.validate_data(): 
print("Data validation failed. Processing terminated.") 
return 
total_assets = self.data[self.data['Account'].str.contains("Cash|Accounts Receivable|Inventory")]['Amount'].sum() 
total_liabilities = self.data[self.data['Account'].str.contains("Accounts Payable")]['Amount'].sum() 
total_equity = self.data[self.data['Account'] == 'Equity']['Amount'].values[0] print("\nFinancial Summary:") 
print(f"Total Assets: {total_assets}") 
print(f"Total Liabilities: {total_liabilities}") 
print(f"Total Equity: {total_equity}") 
def main(): 
file_path = "C:/Users/Dell/OneDrive/Desktop/DS Practical/balance_sheet.csv" processor = BalanceSheetProcessor(file_path) processor.process_data() 
if __name__ == "__main__": 
main() 

        `
        const text29 = `
        class Employee: 
def __init__(self,emp_id,name,hours,wage): 
self.emp_id=emp_id 
self.name=name 
self.hours=hours 
self.wage=wage 
def calculate_pay(self): 
return self.hours*self.wage 
def generate_payroll(employees): 
total_payroll=0 
report=[] 
for emp in employees: 
pay=emp.calculate_pay() report.append({'ID':emp.emp_id,'Name':emp.name,'Pay':pay}) total_payroll+=pay 
report.append({'Total Payroll':total_payroll}) 
return report 
employees=[
 Employee(1,'Alice',40,15.00),
 Employee(2,'Bob',35,20.00),
 Employee(3,'Charlie',45,18.00) 
] 
payroll_report=generate_payroll(employees) 
for entry in payroll_report: 
print(entry)

        `
        const text30 = `
        import os 
import uuid 
import pandas as pd 
import sqlite3 as sq 
from datetime import datetime, timedelta 
from pytz import timezone, all_timezones 
input_dir = 'DS Practical' 
input_file = 'C:/Users/Dell/OneDrive/Desktop/DS Practical/VehicleData.csv' 
sDataBaseDir = 'C:/Users/Dell/OneDrive/Desktop/DS Practical' 
os.makedirs(sDataBaseDir, exist_ok=True) 
conn1 = sq.connect(os.path.join(sDataBaseDir, 'Hillman.db')) 
sDataVaultDir = 'C:/Users/Dell/OneDrive/Desktop/DS Practical' os.makedirs(sDataVaultDir, exist_ok=True) 
conn2 = sq.connect(os.path.join(sDataVaultDir, 'datavault.db')) 
base = datetime(2018, 1, 1) 
date_list = [base - timedelta(hours=x) for x in range(1)] 
time_data = [] 
for now_utc in date_list: 
now_utc = now_utc.replace(tzinfo=timezone('UTC'))
sDateTime = now_utc.strftime("%Y-%m-%d %H:%M:%S") 
sDateTimeKey = sDateTime.replace(' ', '-').replace(':', '-') 
time_data.append({ 
'ZoneBaseKey': 'UTC', 
'IDNumber': str(uuid.uuid4()), 
'nDateTimeValue': now_utc, 
'DateTimeValue': sDateTime, 
'DateTimeKey': sDateTimeKey 
}) 
time_frame = pd.DataFrame(time_data) 
time_hub = time_frame[['IDNumber', 'ZoneBaseKey', 'DateTimeKey', 'DateTimeValue']].set_index('IDNumber')
time_hub.to_sql('Process-Time', conn1, if_exists="replace") 
time_hub.to_sql('Hub-Time', conn2, if_exists="replace") 
for now_date in time_frame['nDateTimeValue']: 
for zone in all_timezones: 
now_utc = now_date.replace(tzinfo=timezone('UTC')) 
now_zone = now_utc.astimezone(timezone(zone)) 
sZoneDateTime = now_zone.strftime("%Y-%m-%d %H:%M:%S") 
time_zone_data = { 
'ZoneBaseKey': 'UTC', 
'IDZoneNumber': str(uuid.uuid4()), 
'DateTimeKey': time_frame['DateTimeKey'][0], 
'UTCDateTimeValue': now_utc.strftime("%Y-%m-%d %H:%M:%S"), 
'Zone': zone, 'DateTimeValue': sZoneDateTime 
} 
zone_df = pd.DataFrame([time_zone_data]).set_index('IDZoneNumber') zone_df.to_sql(f'Process-Time-{zone.replace("/", "- ").replace(" ", "")}', conn1, if_exists="replace") 
zone_df.to_sql(f'Satellite-Time-{zone.replace("/", "- ").replace(" ", "")}', conn2, if_exists="replace") 
for conn in [conn1, conn2]: 
conn.execute("VACUUM;") 
print('### Done!! ############################################')

        `
        const text31 = `
        import pandas as pd 
import numpy as np 
from sklearn.preprocessing 
import MinMaxScaler, StandardScaler, OneHotEncoder 
data = { 
'Age': [25, 32, 47, 51, 62], 
'Income': [50000, 60000, 120000, 100000, 110000], 
'Gender': ['Male', 'Female', 'Female', 'Male', 'Female'], 
'Purchased': ['No', 'Yes', 'No', 'Yes', 'Yes'] 
} 
df = pd.DataFrame(data) print("Original Data:") 
print(df) 
scaler = MinMaxScaler() 
df[['Age', 'Income']] = scaler.fit_transform(df[['Age', 'Income']]) 
print("\nNormalized Data (Min-Max Scaling):") 
print(df) 
scaler = StandardScaler() 
df[['Age', 'Income']] = scaler.fit_transform(df[['Age', 'Income']]) 
print("\nStandardized Data (Z-Score Scaling):") 
print(df) 
df['Log_Income'] = np.log(df['Income'] + 1) 
print("\nData after Log Transformation of 'Income':") 
print(df) 
encoder = OneHotEncoder(sparse_output=False) # Change 'sparse' to 'sparse_output' 
encoded_gender = encoder.fit_transform(df[['Gender']]) 
encoded_df = pd.DataFrame(encoded_gender, columns=encoder.get_feature_names_out(['Gender'])) df = pd.concat([df, encoded_df], axis=1).drop('Gender', axis=1) 
print("\nData after One-Hot Encoding 'Gender':") 
print(df) 
df['Age_Binned'] = pd.cut(df['Age'], bins=[0, 30, 50, 100], 
labels=['Young', 'Middle-aged', 'Senior']) 
print("\nData after Binning 'Age':") 
print(df)

        `
        const text32 = `
        import pandas as pd 
from cryptography.fernet import Fernet 
data={'Name':['John','Alice','Bob'],'Age':[28,24,30],'Salary':[500 00,60000,55000],'Gender':['Male','Female','Male']} 
df=pd.DataFrame(data) 
def horizontal_style(df): 
print("Horizontal Style Data (Wide Format):") 
print(df) 
def vertical_style(df): 
df_vertical=pd.melt(df,id_vars=['Name'],var_name='Attribute',v alue_name='Value') 
print("\nVertical Style Data (Long Format):") 
print(df_vertical) def island_style(df): 
print("\nIsland Style Data:") 
grouped=df.groupby('Name') 
for name,group in grouped: 
print(f"\nIsland for {name}:") 
print(group) 
def secure_vault_style(df,column_to_encrypt): 
print("\nSecure Vault Style Data (With Encrypted Salary):") 
key=Fernet.generate_key() 
cipher_suite=Fernet(key) 
df['Encrypted_'+column_to_encrypt]=df[column_to_encrypt].ap ply(lambda x:cipher_suite.encrypt(str(x).encode()).decode()) df_secure_vault=df.drop(columns=[column_to_encrypt]) 
print(df_secure_vault) 
df_secure_vault['Decrypted_'+column_to_encrypt]=df_secure_vault['Encrypted_'+column_to_encrypt].apply(lambda x:cipher_suite.decrypt(x.encode()).decode()) 
print("\nDecrypted Salary for Verification:") print(df_secure_vault[['Name','Decrypted_'+column_to_encrypt] ]) 
horizontal_style(df) 
vertical_style(df)
island_style(df) 
secure_vault_style(df,'Salary')
        `
        const text33 = `
        import pandas as pd 
from openpyxl import Workbook 
from openpyxl.chart import ( 
PieChart3D, 
Reference 
) 
wb_pie_chart = Workbook() 
ws_pie_chart = wb_pie_chart.active 
data = [ 
("Type of Expense", "Amount Spent"), 
("Grocery", 300), 
("Electricity", 150),
("Child Tuition", 125), 
("House Keeping", 35), 
("Gardening", 30), 
("Misl. Expense", 500), 
] 
for row in data: 
ws_pie_chart.append(row) 
pie = PieChart3D() 
labels = Reference(ws_pie_chart, min_col=1, min_row=2, max_row=7) 
data = Reference(ws_pie_chart, min_col=2, min_row=1, max_row=7) 
pie.add_data(data, titles_from_data=True) 
pie.set_categories(labels) pie.title = "Expenditures Pie Chart" 
ws_pie_chart.add_chart(pie, "C10") 
wb_pie_chart.save("C:/Users/Dell/OneDrive/Desktop/DS Practical/pie.xlsx") 
print("data saved")

        `
        

        // Add the rest of your text blocks here (text6, text7, ...)

        // Function to copy text using Clipboard API
        async function copyText(text) {
            try {
                // Use Clipboard API to write text to the clipboard
                await navigator.clipboard.writeText(text);

                // Notify user of success
                const messageElement = document.getElementById("copiedMsg");
                messageElement.innerText = "Text copied successfully!";
                messageElement.style.color = "green";

                // Clear message after 2 seconds
                setTimeout(() => {
                    messageElement.innerText = "";
                }, 2000);
            } catch (err) {
                // Notify user of failure
                const messageElement = document.getElementById("copiedMsg");
                messageElement.innerText = "Failed to copy text. Check your browser permissions.";
                messageElement.style.color = "red";

                console.error("Error copying text: ", err);
            }
        }
    </script>

</body>

</html>
